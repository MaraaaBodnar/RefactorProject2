**Загальний опис**  
Цей проєкт реалізує систему розпізнавання емоцій у мовленні на основі обробки аудіо, витягнення ознак (features) та навчання моделі машинного навчання. Проєкт реалізований у вигляді бібліотеки з чіткою модульною структурою та застосуванням об’єктно-орієнтованих принципів, шаблонів проєктування та модульного тестування.

**Дизайн-принципи**  
Проєкт побудований на основі таких принципів проєктування:  

Single Responsibility Principle (SRP) – кожен клас виконує одну чітко визначену функцію (наприклад, AudioProcessor обробляє звук, FeatureExtractor витягує ознаки).  

Open/Closed Principle (OCP) – класи відкриті для розширення, але закриті для модифікації (наприклад, стратегія шумозниження може змінюватися без зміни AudioProcessor).  

Dependency Inversion Principle (DIP) – залежності задаються через абстракції (стратегії, декоратори), що дозволяє легко змінювати реалізації.  

DRY (Don't Repeat Yourself) – спільна логіка винесена у спільні класи або методи.  

Modular Design – чіткий поділ на незалежні модулі.  

**Структура та організація коду**  
project_root/  
│  
├── audio_processing.py  
├── feature_extraction.py  
├── model.py  
├── utils.py  
├── __init__.py  
│                          
└── test_main.py  

**Використані шаблони проєктування**  
У проєкті реалізовано наступні шаблони проектування (Design Patterns):  

1. *Strategy Pattern (DefaultNoiseReduction, SimpleNoiseReduction)*  
Дає змогу AudioProcessor використовувати різні алгоритми шумозниження без зміни свого коду.  

Інтерфейс стратегії: NoiseReductionStrategy  

***Приклад використання:***  
processor = AudioProcessor(noise_reduction_strategy=DefaultNoiseReduction())  

2. *Facade Pattern (FeatureExtractor)*  
Спрощує інтерфейс до кількох складних підсистем (MFCC, спектрограма, mel).  

Клієнт може викликати extract_mfcc, не думаючи про реалізацію.  

3. *Decorator Pattern (ModelLogger)*  
Обгортає модель EmotionRecognitionModel і логує час виконання train та predict.  

4. *Factory Method (implicit)* – створення моделі відбувається централізовано в EmotionRecognitionModel.__init__, і його можна вважати реалізацією фабричного методу для побудови Keras-моделі.  

**Структура модульних тестів**  
Тестування реалізоване за допомогою pytest. Загалом реалізовано 20 тестів, які покривають усі основні функціональні блоки:  

***Категорії тестів:***  

*AudioProcessor Tests*  

- Завантаження аудіо  
- Нормалізація  
- Шумозниження зі стратегіями  
- Обробка нульових сигналів  

*FeatureExtractor Tests*  

- MFCC, спектрограма, mel  
- Робота фасаду  
- EmotionRecognitionModel Tests  
- Побудова моделі  
- Передбачення  
- Навчання  
- Збереження / завантаження  
- Обробка помилкових входів  

*Decorator Tests*  

- Перевірка виводу часу  
- Делегування методів  
- Utils / Загальні  
- Збереження та завантаження LabelEncoder  
- Імпорти  
- Обробка edge-case (порожнє аудіо)  
 
